# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uJZX_luTFhNDVI4YxgvRPa0d611Y5qkn
"""

!pip install ultralytics

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="38Bb4xtLGTD5P5vdhm6M")
workspace = rf.workspace()
print(workspace)

project = rf.workspace("trafficsignaldetection-lti5q").project("traffic_signal_detection")
dataset = project.version(1).download("yolov8")

import os
import cv2
import matplotlib.pyplot as plt

# Define the path to the dataset images
image_path = os.path.join(dataset.location, 'train', 'images')

# Get a list of image files
image_files = [f for f in os.listdir(image_path) if f.endswith(('.jpg', '.jpeg', '.png'))]

# Display information for the first few images
num_images_to_display = 3

if not image_files:
    print(f"No image files found in {image_path}")
else:
    print(f"Found {len(image_files)} images in {image_path}")
    print("\nInspecting first few images:")

    plt.figure(figsize=(15, 5))
    for i, img_name in enumerate(image_files[:num_images_to_display]):
        img_full_path = os.path.join(image_path, img_name)
        img = cv2.imread(img_full_path)

        if img is not None:
            # OpenCV loads images as BGR, convert to RGB for matplotlib
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            print(f"  Image: {img_name}, Shape: {img.shape} (Height, Width, Channels)")

            plt.subplot(1, num_images_to_display, i + 1)
            plt.imshow(img_rgb)
            plt.title(f"Size: {img.shape[1]}x{img.shape[0]}")
            plt.axis('off')
        else:
            print(f"  Could not load image: {img_name}")
    plt.tight_layout()
    plt.show()

"""To visualize the bounding boxes, we need to read the YOLO format `.txt` annotation files associated with each image. These files contain normalized coordinates, so we'll convert them to pixel coordinates to draw on the image. Each line in the `.txt` file typically represents an object with `class_id center_x center_y width height`."""

import os
import cv2
import matplotlib.pyplot as plt

# Define paths
image_path = os.path.join(dataset.location, 'train', 'images')
label_path = os.path.join(dataset.location, 'train', 'labels')

def plot_boxes(img, labels, class_names):
    h, w, _ = img.shape
    for label in labels:
        # YOLO format: class_id, center_x, center_y, width, height (normalized)
        class_id, x_center, y_center, box_width, box_height = map(float, label.split(' '))

        # Convert normalized coordinates to pixel coordinates
        x_center *= w
        y_center *= h
        box_width *= w
        box_height *= h

        x1 = int(x_center - box_width / 2)
        y1 = int(y_center - box_height / 2)
        x2 = int(x_center + box_width / 2)
        y2 = int(y_center + box_height / 2)

        # Draw rectangle (bounding box)
        color = (0, 255, 0) # Green color
        thickness = 2
        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)

        # Put class name (optional, if you have class names)
        class_name = class_names[int(class_id)] if class_names else str(int(class_id))
        cv2.putText(img, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)
    return img

# Load class names from data.yaml (assuming it's available)
import yaml
with open(os.path.join(dataset.location, 'data.yaml'), 'r') as f:
    data_yaml = yaml.safe_load(f)
    class_names = data_yaml['names']

# Get a list of image files
image_files = [f for f in os.listdir(image_path) if f.endswith(('.jpg', '.jpeg', '.png'))]

num_images_to_display = 3

if not image_files:
    print(f"No image files found in {image_path}")
else:
    print(f"Found {len(image_files)} images in {image_path}")
    print("\nInspecting first few images with bounding boxes:")

    plt.figure(figsize=(15, 5))
    for i, img_name in enumerate(image_files[:num_images_to_display]):
        img_full_path = os.path.join(image_path, img_name)
        label_name = img_name.replace(os.path.splitext(img_name)[1], '.txt')
        label_full_path = os.path.join(label_path, label_name)

        img = cv2.imread(img_full_path)

        if img is not None:
            # Read labels
            labels = []
            if os.path.exists(label_full_path):
                with open(label_full_path, 'r') as f:
                    labels = f.readlines()
            else:
                print(f"  No label file found for {img_name}")

            # Draw bounding boxes
            img_with_boxes = plot_boxes(img.copy(), labels, class_names)

            # OpenCV loads images as BGR, convert to RGB for matplotlib
            img_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)

            plt.subplot(1, num_images_to_display, i + 1)
            plt.imshow(img_rgb)
            plt.title(f"Image with BBoxes: {img_name}")
            plt.axis('off')
        else:
            print(f"  Could not load image: {img_name}")
    plt.tight_layout()
    plt.show()

from ultralytics import YOLO
model = YOLO('yolov8n.pt')  # Nano for speed; use yolov8s.pt for better accuracy
results = model.train(data='traffic_signal_detection-1/data.yaml', epochs=10, imgsz=512)

"""Now that the model is trained, let's evaluate its performance on the validation set using `model.val()`.

You can now test the trained model on a custom image. Provide the path to your image, and the model will perform object detection and display the results.
"""

import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO
import os

# Ensure the model is loaded (it should be from previous steps, but good practice to ensure)
# model = YOLO('yolov8n.pt') # Uncomment and run if model is not already loaded in the environment

# Hardcoded path to the image for prediction
image_to_predict_path = "/content/traffic_signal_detection-1/test/images/traffic-light-990-_jpg.rf.322a30fb2c62af55c1d3e95c5333987b.jpg"

# Check if the file exists
if not os.path.exists(image_to_predict_path):
    print(f"Error: Image not found at {image_to_predict_path}")
else:
    # Perform prediction
    results = model.predict(source=image_to_predict_path, conf=0.25)  # conf is confidence threshold

    # Iterate through results and display
    for r in results:
        im_array = r.plot()  # plot a BGR numpy array of predictions
        im_rgb = cv2.cvtColor(im_array, cv2.COLOR_BGR2RGB) # convert to RGB

        plt.figure(figsize=(10, 10))
        plt.imshow(im_rgb)
        plt.title("Model Prediction")
        plt.axis('off')
        plt.show()

"""### 1. Access Specific Metrics

Let's retrieve and display specific global and per-class metrics from the `metrics` object.
"""

print("--- Overall Metrics ---")
print(f"mAP50: {metrics.box.map50}") # Mean Average Precision at IoU=0.50
print(f"mAP50-95: {metrics.box.map}") # Mean Average Precision over IoU=0.50:0.95
print(f"Overall Precision: {metrics.box.mp}") # Mean Precision
print(f"Overall Recall: {metrics.box.mr}") # Mean Recall

print("\n--- Per-Class Metrics ---")
# 'names' attribute from data.yaml stores class names
for i, class_name in enumerate(data_yaml['names']):
    print(f"Class {class_name}:")
    # metrics.box.p[i] is precision for class i
    # metrics.box.r[i] is recall for class i
    # metrics.box.ap50[i] is AP50 for class i
    # metrics.box.ap[i] is AP50-95 for class i
    print(f"  Precision: {metrics.box.p[i]:.4f}")
    print(f"  Recall: {metrics.box.r[i]:.4f}")
    print(f"  AP50: {metrics.box.ap50[i]:.4f}")
    print(f"  AP50-95: {metrics.box.ap[i]:.4f}")

"""### 2. Visualize the Confusion Matrix

The confusion matrix helps visualize the performance of an algorithm, typically in supervised learning, but adapted for object detection to show how often objects are correctly detected and classified versus being misclassified or missed.
"""

import matplotlib.pyplot as plt

# Plot the confusion matrix (normalized)
# The plot() method saves the figure to runs/detect/val/confusion_matrix.png by default.
# It also returns the matplotlib figure object if you want to display it directly.
confusion_matrix_fig = metrics.confusion_matrix.plot(normalize=True)
plt.show()

"""### 3. Plot Precision-Recall (PR) Curves

Precision-Recall curves are essential for object detection to understand the trade-off between precision and recall across different detection thresholds.
"""

# Plot all Precision-Recall curves (one for each class and an overall)
# The plot() method saves the figure to runs/detect/val/P_curve.png by default
# metrics.plot(plot_curves=True) also generates these, but we can access them directly.

# The metrics object stores these plots, you can replot them or inspect the arrays
# For simplicity, let's just show how to access the saved plots or recreate a plot.

# Ultralytics saves these plots to the results directory. We can load and display them.
import glob
from IPython.display import Image, display
import os

val_run_dir = metrics.save_dir

# The plots are generated automatically by model.val() and saved to metrics.save_dir
# Do NOT call metrics.plot() as it's not a valid method on DetMetrics object.

print(f"Checking contents of {val_run_dir}:")
if os.path.exists(val_run_dir):
    print(os.listdir(val_run_dir))
else:
    print(f"Directory {val_run_dir} does not exist.")

print(f"Looking for BoxP_curve.png in {val_run_dir}")
pr_curve_path = os.path.join(val_run_dir, 'BoxP_curve.png') # Corrected filename

if os.path.exists(pr_curve_path):
    print("Displaying Precision-Recall curve:")
    display(Image(filename=pr_curve_path))
else:
    print(f"Precision-Recall curve image not found at {pr_curve_path}. "
          "This should have been generated by model.val(). Please check the directory manually if needed.")

"""### 4. Plot F1-Confidence Curve

This curve shows the F1-score (harmonic mean of precision and recall) at various confidence thresholds, helping you pick an optimal threshold for your application.
"""

import os
from IPython.display import Image, display

val_run_dir = metrics.save_dir # Ensure val_run_dir is correctly set

f1_curve_path = os.path.join(val_run_dir, 'BoxF1_curve.png') # Corrected filename

if os.path.exists(f1_curve_path):
    print("Displaying F1-Confidence curve:")
    display(Image(filename=f1_curve_path))
else:
    print(f"F1-Confidence curve image not found at {f1_curve_path}. "
          "This should have been generated by model.val(). Please check the directory manually if needed.")

metrics = model.val(data='traffic_signal_detection-1/data.yaml')
print(metrics)

